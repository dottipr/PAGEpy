{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a35ffc44",
   "metadata": {},
   "source": [
    "# R SingleCellExperiment Object to Disk (for Python Usage)\n",
    "\n",
    "**TODO:** Add this documentation to local readme file\n",
    "\n",
    "**Author:** Prisca Dotti\n",
    "\n",
    "**Last modified:** 12.08.2025\n",
    "\n",
    "This script imports R datasets saved as `.rds` files into Python and saves them in a format compatible with the PAGEpy pipeline.\n",
    "\n",
    "📋 **Requirements**\n",
    "\n",
    "- R with the `SingleCellExperiment` package installed  \n",
    "- Python package `anndata2ri`  \n",
    "  Install via:  \n",
    "  `%pip install anndata2ri`\n",
    "\n",
    "🗂 **Outputs**\n",
    "\n",
    "Creates the following files in a given output directory:\n",
    "\n",
    "1. `count_matrix.mtx` — count matrix in Matrix Market format  \n",
    "2. `gene_names.txt` — list of gene names  \n",
    "3. `sample_names.txt` — list of sample IDs  \n",
    "4. `response_labels.csv` — CSV file containing sample response labels\n",
    "\n",
    "🔍 **Context**\n",
    "\n",
    "This project currently works with an HIV single-cell dataset. The goal here is to convert bulk dataset R data to match the single-cell data structure, by changing names of variables, columns, rows, and so on, to make sure that the data is compatible with the PAGEpy pipeline.\n",
    "\n",
    "When running the package with a new dataset, this could be a good starting point to process the data (at least for people unfamiliar with R).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd264ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.io import mmwrite\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2a996-165c-4a35-a38b-b7ce7dd47437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anndata2ri\n",
      "  Downloading anndata2ri-2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: anndata in /home/jovyan/.local/share/hatch/env/virtual/pagepy/RRSnIvUW/pagepy/lib/python3.12/site-packages (from anndata2ri) (0.10.9)\n",
      "Collecting rpy2>=3.5.2 (from anndata2ri)\n",
      "  Downloading rpy2-3.6.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting tzlocal (from anndata2ri)\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting rpy2-rinterface>=3.6.2 (from rpy2>=3.5.2->anndata2ri)\n",
      "  Downloading rpy2_rinterface-3.6.2.tar.gz (79 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\\"
     ]
    }
   ],
   "source": [
    "%pip install anndata2ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "949a5f40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'anndata2ri'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01manndata2ri\u001b[39;00m\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mload_ext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrpy2.ipython\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m anndata2ri.set_ipython_converter()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'anndata2ri'"
     ]
    }
   ],
   "source": [
    "import anndata2ri\n",
    "%load_ext rpy2.ipython\n",
    "anndata2ri.set_ipython_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%R\n",
    "# # Install BiocManager if not already installed\n",
    "# if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
    "#     install.packages(\"BiocManager\")\n",
    "\n",
    "# # Install SingleCellExperiment\n",
    "# BiocManager::install(\"SingleCellExperiment\")\n",
    "\n",
    "# # Also install other potentially needed packages\n",
    "# BiocManager::install(c(\"SingleCellExperiment\", \"SummarizedExperiment\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d37584",
   "metadata": {},
   "source": [
    "Load .rds file in R and convert to AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3538480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o adata\n",
    "library(SingleCellExperiment)\n",
    "\n",
    "# Read the SingleCellExperiment object\n",
    "sce <- readRDS(\"../../bulk_data/GEO_singlecellexperiment_11ds.rds\")\n",
    "\n",
    "# Check the structure\n",
    "print(\"SingleCellExperiment object:\")\n",
    "print(sce)\n",
    "print(\"Available assays:\")\n",
    "print(names(assays(sce)))\n",
    "print(\"colData columns:\")\n",
    "print(colnames(colData(sce)))\n",
    "print(\"rowData columns:\")\n",
    "print(colnames(rowData(sce)))\n",
    "\n",
    "# Convert to AnnData (this will automatically transfer to Python)\n",
    "adata <- sce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea346f1",
   "metadata": {},
   "source": [
    "Verify the AnnData object in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e76212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AnnData object received from R:\")\n",
    "print(adata)\n",
    "print(f\"\\nShape: {adata.shape}\")\n",
    "print(\n",
    "    f\"Available layers: {list(adata.layers.keys()) if adata.layers else 'No layers'}\")\n",
    "print(f\"obs columns: {adata.obs.columns.tolist()}\")\n",
    "print(f\"var columns: {adata.var.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dd10a",
   "metadata": {},
   "source": [
    "Extract and save required data to run PAGEpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8299a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out samples labeled as \"partial\" from adata.obs['Response']\n",
    "\n",
    "if 'Response' in adata.obs.columns:\n",
    "    print(\"Before filtering:\", adata.shape, \"Response counts:\")\n",
    "    print(adata.obs['Response'].value_counts())\n",
    "\n",
    "    # Keep only samples with Response \"yes\" or \"no\"\n",
    "    adata = adata[adata.obs['Response'].isin(['yes', 'no'])].copy()\n",
    "\n",
    "    print(\"After filtering:\", adata.shape, \"Response counts:\")\n",
    "    print(adata.obs['Response'].value_counts())\n",
    "else:\n",
    "    print(\"⚠ 'Response' column not found; skipping filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_files(adata, output_dir=\"output\"):\n",
    "    \"\"\"Extract and save the data in PAGEpy required formats.\"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. Get the scalelogcounts matrix\n",
    "    # if 'scalelogcounts' in adata.layers:\n",
    "    #     count_matrix = adata.layers['scalelogcounts']\n",
    "    #     print(\"✓ Found scalelogcounts in layers\")\n",
    "    if 'counts' in adata.layers:\n",
    "        count_matrix = adata.layers['counts']\n",
    "        print(\"✓ Found counts in layers\")\n",
    "    elif hasattr(adata, 'X') and adata.X is not None:\n",
    "        count_matrix = adata.X\n",
    "        print(\"✓ Using main X matrix\")\n",
    "    else:\n",
    "        print(\"⚠ Could not find count matrix\")\n",
    "        return\n",
    "\n",
    "    # Convert to dense array if sparse\n",
    "    if hasattr(count_matrix, 'toarray'):\n",
    "        count_matrix_dense = count_matrix.toarray()\n",
    "    else:\n",
    "        count_matrix_dense = np.array(count_matrix)\n",
    "    count_matrix_dense = count_matrix_dense.T  # To match HIV dataset\n",
    "\n",
    "    print(f\"Count matrix shape: {count_matrix_dense.shape} (genes × samples)\")\n",
    "\n",
    "    # 2. Get gene names\n",
    "    if 'gene_name' in adata.var.columns:\n",
    "        gene_names = adata.var['gene_name'].tolist()\n",
    "        print(f\"✓ Found {len(gene_names)} gene names from 'gene_name' column\")\n",
    "    else:\n",
    "        gene_names = adata.var.index.tolist()\n",
    "        print(f\"✓ Using var index as gene names: {len(gene_names)} genes\")\n",
    "        print(\"Available var columns:\", adata.var.columns.tolist())\n",
    "\n",
    "    # 3. Get sample IDs\n",
    "    sample_ids = adata.obs.index.tolist()\n",
    "    print(f\"✓ Found {len(sample_ids)} sample IDs\")\n",
    "\n",
    "    # 4. Get Response labels\n",
    "    if 'Response' in adata.obs.columns:\n",
    "        response_labels = adata.obs['Response']\n",
    "        print(f\"✓ Found Response column\")\n",
    "        print(\"Response distribution:\", response_labels.value_counts().to_dict())\n",
    "    else:\n",
    "        print(\"⚠ 'Response' column not found in obs\")\n",
    "        print(\"Available obs columns:\", adata.obs.columns.tolist())\n",
    "        response_labels = None\n",
    "\n",
    "    # Save files\n",
    "    print(\"\\nSaving files...\")\n",
    "\n",
    "    # 1. Count matrix as .mtx\n",
    "    sparse_matrix = csr_matrix(count_matrix_dense)\n",
    "    mmwrite(os.path.join(output_dir, 'count_matrix.mtx'), sparse_matrix)\n",
    "    print(\"✓ Saved count_matrix.mtx\")\n",
    "\n",
    "    # 2. Gene names as .txt\n",
    "    with open(os.path.join(output_dir, 'gene_names.txt'), 'w') as f:\n",
    "        for gene in gene_names:\n",
    "            f.write(f\"{gene}\\n\")\n",
    "    print(\"✓ Saved gene_names.txt\")\n",
    "\n",
    "    # 3. Sample names as .txt\n",
    "    with open(os.path.join(output_dir, 'sample_names.txt'), 'w') as f:\n",
    "        for sample in sample_ids:\n",
    "            f.write(f\"{sample}\\n\")\n",
    "    print(\"✓ Saved sample_names.txt\")\n",
    "\n",
    "    # 4. Response labels as .csv\n",
    "    if response_labels is not None:\n",
    "        labels_df = pd.DataFrame({\n",
    "            'Sample': sample_ids,\n",
    "            'Status': response_labels.values\n",
    "        })\n",
    "        labels_df.to_csv(os.path.join(\n",
    "            output_dir, 'response_labels.csv'), index=False)\n",
    "        print(\"✓ Saved response_labels.csv\")\n",
    "\n",
    "    # # 5. Save AnnData object for future use # <- doesn't work\n",
    "    # adata.write(os.path.join(output_dir, 'data.h5ad'))\n",
    "    # print(\"✓ Saved data.h5ad (AnnData format)\")\n",
    "\n",
    "    print(f\"\\nAll files saved to '{output_dir}' directory!\")\n",
    "\n",
    "    return {\n",
    "        'count_matrix': count_matrix_dense,\n",
    "        'gene_names': gene_names,\n",
    "        'sample_ids': sample_ids,\n",
    "        'response_labels': response_labels.values if response_labels is not None else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b953d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the extraction\n",
    "extracted_data = save_data_files(\n",
    "    adata=adata, output_dir=\"../../bulk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f16c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pagepy-env)",
   "language": "python",
   "name": "pagepy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
